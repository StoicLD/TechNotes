# Vtuber计划

## :file_cabinet: 零，前言

-----

总之毕业设计准备做一个Vtuber系统。

我的核心不是在于live2D的生成，那个需要用到很多的机器学习知识，也不是我三个月内可以实现的。

虽然机器学习还是可以学习一点。

我打算先不参考任何的具体实现，自己在试用一段时间facefig，搞清楚整个vtuber的制作流程之后。

此处是OneNote上的补充区域，或者说正式版本区域。

目前我是用OneNote作为草稿区。Typora+OneDrive作为缓存区，博客当作正式区域。

## :six_pointed_star: 一，功能需求

-----------------

### :slightly_smiling_face:（1）人脸识别

人脸识别部分曲折的探索了几条道路，最后又回到了原点。

1. 使用CVVtuber Example里面自带的OpenCV for Unity和Dlib的识别
2. 使用开源项目Open Vtuber的head-pose-estimate，这个方案需要外部启动一个python脚本（而且很吃资源）
3. 使用卡尔曼滤波



### :m: （2）Live2D与3D模型处理

**第一阶段：**

1. **Live的面部控制功能**

   这一部分就是参数控制。摄像头前的人面部被摄像头捕捉，参数动态的传递给程序，程序控制模型面部变换。

2. **3D的模型初步的控制功能**

   同2D，只不过使用的不再是Cubism Live2D的SDK，而是直接使用BlendShape相关的控制功能。
   
   3D暂时不做，或者说只做一点



**第二阶段：**

1. **参数暴露**

   提供给用户的可控制参数。使得用户可以自定义。

2. **表情控制**

   参数暴露的目的就是给用户自定义的表情调整。
   
   用户在编辑模式下手动调整参数设置好的表情可以被保存为表情
   
   表情可以绑定按键，按下按键之后就可以切换表情。
   
3. **移动人物**

   默认Ctrl + 鼠标移动人物模型

4. **3D模型的主要控制**

   加入平滑，BlendShape的精确控制

**第三阶段：**

1. 自定义模型/模型导入
2. 按键绑定
3. 



### :closed_book:（3）UI界面

1. 隐藏UI
2. 自定义参数调整列表